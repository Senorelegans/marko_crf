{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Implementation of Conditional Random Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/lancifollia/crf\n",
    "https://homepages.inf.ed.ac.uk/csutton/publications/crftut-fnt.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "heading_collapsed": true
   },
   "source": [
    "### The corpus comes from [CoNLL 2000 Chunking Data] (https://www.clips.uantwerpen.be/conll2000/chunking/). \n",
    "\n",
    "First line example: \n",
    "\n",
    "Confidence NN B-NP\n",
    "\n",
    "The first column contains the current word, the second its part-of-speech (POS) tag as derived by the Brill tagger and the third its chunk tag \n",
    "\n",
    "For each paragraph there is an empty line seperating the paragraphs\n",
    "\n",
    "Now we will write a function to seperate the words (word and POS) from the labels/y (chunk tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(f1):\n",
    "    \"\"\" Read the corpus file and append to lists.\n",
    "    \n",
    "    INPUT: corpus file\n",
    "    Output:\n",
    "    X - list of paragraphs of all words besides label\n",
    "    Y - list of labels for each line in paragraph\n",
    "    d - list of tuples corresponding to X,Y from each paragraph\n",
    "         first paragraph X (word/pos) is \\n \" , d[0][0])\n",
    "         first paragraph Y is \\n \" , d[0][1])\n",
    "    \n",
    "    \"\"\"\n",
    "    X = list()\n",
    "    Y = list()\n",
    "    d = list()\n",
    "    \n",
    "    with open(f1,\"r\") as infile:\n",
    "        for line in infile:\n",
    "            line = line.strip().split()\n",
    "            if len(line) > 0:\n",
    "                X.append(line[:-1])\n",
    "                Y.append(line[-1])\n",
    "            if len(line) == 0:  \n",
    "                if len(X) > 0:\n",
    "                    d.append((X,Y)) # Append the X and Y to data if you go to new paragraph\n",
    "                    X = list()\n",
    "                    Y = list()      # Re-initialize list \n",
    "    d.append((X,Y)) # Append the last X and Y to data if you go to new paragraph\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of first paragraph X (word/pos) is \n",
      "  [['Confidence', 'NN'], ['in', 'IN'], ['the', 'DT'], ['pound', 'NN'], ['is', 'VBZ'], ['widely', 'RB'], ['expected', 'VBN'], ['to', 'TO'], ['take', 'VB'], ['another', 'DT'], ['sharp', 'JJ'], ['dive', 'NN'], ['if', 'IN'], ['trade', 'NN'], ['figures', 'NNS'], ['for', 'IN'], ['September', 'NNP'], [',', ','], ['due', 'JJ'], ['for', 'IN'], ['release', 'NN'], ['tomorrow', 'NN'], [',', ','], ['fail', 'VB'], ['to', 'TO'], ['show', 'VB'], ['a', 'DT'], ['substantial', 'JJ'], ['improvement', 'NN'], ['from', 'IN'], ['July', 'NNP'], ['and', 'CC'], ['August', 'NNP'], [\"'s\", 'POS'], ['near-record', 'JJ'], ['deficits', 'NNS'], ['.', '.']]\n",
      "list of first paragraph Y is \n",
      "  ['B-NP', 'B-PP', 'B-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-SBAR', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'O', 'B-ADJP', 'B-PP', 'B-NP', 'B-NP', 'O', 'B-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'O']\n",
      "list of 2nd paragraph X (word/pos) is \n",
      "  [['Chancellor', 'NNP'], ['of', 'IN'], ['the', 'DT'], ['Exchequer', 'NNP'], ['Nigel', 'NNP'], ['Lawson', 'NNP'], [\"'s\", 'POS'], ['restated', 'VBN'], ['commitment', 'NN'], ['to', 'TO'], ['a', 'DT'], ['firm', 'NN'], ['monetary', 'JJ'], ['policy', 'NN'], ['has', 'VBZ'], ['helped', 'VBN'], ['to', 'TO'], ['prevent', 'VB'], ['a', 'DT'], ['freefall', 'NN'], ['in', 'IN'], ['sterling', 'NN'], ['over', 'IN'], ['the', 'DT'], ['past', 'JJ'], ['week', 'NN'], ['.', '.']]\n",
      "list of 2nd paragraph Y is \n",
      "  ['O', 'B-PP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'B-NP', 'I-NP', 'I-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'I-NP', 'B-VP', 'I-VP', 'I-VP', 'I-VP', 'B-NP', 'I-NP', 'B-PP', 'B-NP', 'B-PP', 'B-NP', 'I-NP', 'I-NP', 'O']\n"
     ]
    }
   ],
   "source": [
    "d = read_corpus(\"data/chunking_small/smallest_train.data\")\n",
    "print(\"list of first paragraph X (word/pos) is \\n \" , d[0][0])\n",
    "print(\"list of first paragraph Y is \\n \" , d[0][1])\n",
    "\n",
    "print(\"list of 2nd paragraph X (word/pos) is \\n \" , d[1][0])\n",
    "print(\"list of 2nd paragraph Y is \\n \" , d[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     18,
     36,
     78
    ]
   },
   "outputs": [],
   "source": [
    "class FeatureSet():\n",
    "    \n",
    "    feature_dic = dict()\n",
    "    observation_set = set()\n",
    "    empirical_counts = Counter()\n",
    "    num_features = 0\n",
    "\n",
    "    label_dic = {\"*\": 0} # Initialize dictionaries with filler starting values\n",
    "    label_array = [\"*\"]\n",
    "    prev_y = 0         # Initialize starting index as 0\n",
    "    features = []\n",
    "    training_feature_data = []\n",
    "    \n",
    "    d = read_corpus(\"data/chunking_small/smallest_train.data\")\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_labels(self, Y, t):     \n",
    "        \"\"\"\n",
    "        INPUT - \n",
    "            X = list of paragraphs X (word/pos)\n",
    "            Y = list of paragraphs Y (word/pos)\n",
    "            t = time in paragraph\n",
    "            label_dic = label dictionary with label then index    {'*': 0, 'B-NP': 1}\n",
    "            label_array = label\n",
    "        OUTPUT - \n",
    "        \"\"\"            \n",
    "        try:\n",
    "            y = self.label_dic[Y[t]]   # Check to see if label is seen before\n",
    "        except KeyError:\n",
    "            y = len(self.label_dic)\n",
    "            self.label_dic[Y[t]] = y    # put new number in for label\n",
    "            self.label_array.append(Y[t]) # Append label name to array\n",
    "        self.y = y\n",
    "        \n",
    "    def get_features(self, X,t):\n",
    "        \"\"\"\n",
    "        INPUT - \n",
    "            X = list of paragraphs X (word/pos)\n",
    "            t = time in paragraph\n",
    "        OUTPUT - \n",
    "            features = list of features\n",
    "                feature name: word or pos (space seperated)\n",
    "        \"\"\"   \n",
    "        features = []\n",
    "\n",
    "        length = len(X)\n",
    "        #For current line\n",
    "        features.append('U[0]:%s' % X[t][0])\n",
    "        features.append('POS_U[0]:%s' % X[t][1])\n",
    "    \n",
    "        if t < length-1:\n",
    "            features.append('U[+1]:%s' % (X[t+1][0]))\n",
    "            features.append('B[0]:%s %s' % (X[t][0], X[t+1][0]))\n",
    "            features.append('POS_U[+1]:%s' % X[t+1][1])\n",
    "            features.append('POS_B[0]:%s %s' % (X[t][1], X[t+1][1]))\n",
    "            # print('POS_B[0]:%s %s' % (X[t][1], X[t+1][1]))\n",
    "            if t < length-2:\n",
    "                features.append('U[+2]:%s' % (X[t+2][0]))\n",
    "                features.append('POS_U[+2]:%s' % (X[t+2][1]))\n",
    "                features.append('POS_B[+1]:%s %s' % (X[t+1][1], X[t+2][1]))\n",
    "                features.append('POS_T[0]:%s %s %s' % (X[t][1], X[t+1][1], X[t+2][1]))\n",
    "        if t > 0:\n",
    "            features.append('U[-1]:%s' % (X[t-1][0]))\n",
    "            features.append('B[-1]:%s %s' % (X[t-1][0], X[t][0]))\n",
    "            features.append('POS_U[-1]:%s' % (X[t-1][1]))\n",
    "            features.append('POS_B[-1]:%s %s' % (X[t-1][1], X[t][1]))\n",
    "            if t < length-1:\n",
    "                features.append('POS_T[-1]:%s %s %s' % (X[t-1][1], X[t][1], X[t+1][1]))\n",
    "            if t > 1:\n",
    "                features.append('U[-2]:%s' % (X[t-2][0]))\n",
    "                features.append('POS_U[-2]:%s' % (X[t-2][1]))\n",
    "                features.append('POS_B[-2]:%s %s' % (X[t-2][1], X[t-1][1]))\n",
    "                features.append('POS_T[-2]:%s %s %s' % (X[t-2][1], X[t-1][1], X[t][1]))    \n",
    "        return features\n",
    "        \n",
    "\n",
    "    def add_features(self, features):\n",
    "        \"\"\"\n",
    "        INPUT - \n",
    "            features = list of features from current line\n",
    "                feature name: word or pos (space seperated)\n",
    "                       'U[0]:%s'\n",
    "        OUTPUT -\n",
    "            updated dictionaries\n",
    "                feature_dic[f][(prev_y, y)]\n",
    "                empirical_counts[ feature_dic[f][(prev_y, y)] ]\n",
    "                \n",
    "            total amount of features\n",
    "                num_features\n",
    "        \"\"\"\n",
    "        y = self.y\n",
    "        prev_y = self.prev_y\n",
    "\n",
    "        \n",
    "        for f in features:\n",
    "\n",
    "            if f in self.feature_dic.keys():\n",
    "                \n",
    "                #For prev_y y\n",
    "                if (prev_y,y) in self.feature_dic[f].keys():\n",
    "                    self.empirical_counts[ self.feature_dic[f][(prev_y, y)] ] += 1\n",
    "                else:\n",
    "                    self.feature_dic[f][(prev_y, y)] = self.num_features\n",
    "                    self.empirical_counts[self.num_features] += 1\n",
    "                    self.num_features += 1\n",
    "\n",
    "                #For current y only  (-1,y)\n",
    "                if (-1,y) in  self.feature_dic[f].keys():\n",
    "                    self.empirical_counts[ self.feature_dic[f][(-1, y)] ] += 1\n",
    "                else:\n",
    "                    self.feature_dic[f][(-1, y)] = self.num_features\n",
    "                    self.empirical_counts[self.num_features] += 1\n",
    "                    self.num_features += 1\n",
    "\n",
    "            # If you havent seen feature before \n",
    "            else:               \n",
    "                self.feature_dic[f] = dict()                   # Create new dic for that feature\n",
    "\n",
    "                #For prev y and y\n",
    "                self.feature_dic[f][(prev_y, y)] = self.num_features\n",
    "                self.empirical_counts[self.num_features] += 1\n",
    "                self.num_features += 1\n",
    "\n",
    "                # For current y only\n",
    "                self.feature_dic[f][(-1, y)] = self.num_features\n",
    "                self.empirical_counts[self.num_features] += 1\n",
    "                self.num_features += 1\n",
    "                      \n",
    "        self.prev_y = y # when done adding set previous y   \n",
    "        \n",
    "        \n",
    "    def get_feature_data(self, X, t, features):\n",
    "        \"\"\"\n",
    "        INPUT - \n",
    "                feature_dic[f][(prev_y, y)]     Now filled in from previous loop\n",
    "        OUTPUT -\n",
    "                feature_list_dic[(prev_y, y)] = feature_id\n",
    "                \n",
    "                training_feature_data\n",
    "                \n",
    "                    [paragraph][sentence][word] dic of [prev y, y] or current[-1,y] with a index of where it is in features\n",
    "                    Example from first timepoint\n",
    "                    [((0, 1), {0, 2, 4, 6, 8, 10, 12, 14, 16, 18}), ((-1, 1), {1, 3, 5, 7, 9, 11, 13, 15, 17, 19}), \n",
    "                    ((1, 3), {1705, 90, 506, 1709}), ((-1, 3), {1706, 397, 399, 1429, 91}), ((3, 3), \n",
    "                    {1428, 396, 398, 391}), ((6, 1), {466}), ((2, 1), {1760, 1761, 1762, 719, 1757, 1758, 1759}),\n",
    "                    ((1, 1), {749}), ((7, 8), {652}), ((-1, 8), {653}), ((7, 7), {1210, 1212, 1206, 1214}), \n",
    "                    ((-1, 7), {1215, 1211, 1213, 1207}), ((5, 5), {254}), ((-1, 5), {255}), ((4, 5), {864})]\n",
    "\n",
    "        \"\"\"\n",
    "        feature_list_dic = dict()\n",
    "\n",
    "        for f in features:\n",
    "            # feature_dic[f][(prev_y, y)]\n",
    "            for (prev_y, y), feature_id in self.feature_dic[f].items():  # get label and feature id\n",
    "                if (prev_y, y) in feature_list_dic.keys():\n",
    "                    feature_list_dic[(prev_y, y)].add(feature_id)        # \n",
    "                else:\n",
    "                    feature_list_dic[(prev_y, y)] = {feature_id}\n",
    "\n",
    "        l = [ ((prev_y, y), feature_ids) for (prev_y, y), feature_ids in feature_list_dic.items() ]\n",
    "        return l\n",
    "#         print(l)\n",
    "#         print(\"*********\")\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F = FeatureSet()\n",
    "for X, Y in F.d:\n",
    "    for t in range(len(X)):\n",
    "        F.get_labels(Y, t)\n",
    "        features = F.get_features(X,t)\n",
    "        F.add_features(features)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "# # Get \n",
    "for X, Y in F.d:\n",
    "    for t in range(len(X)):\n",
    "        features = F.get_features(X,t)\n",
    "        l = F.get_feature_data(X,t, features)\n",
    "    F.training_feature_data.append(l)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features are 1856\n",
      "length of feature dic is 750\n",
      "Labels are : {'*': 0, 'B-NP': 1, 'B-PP': 2, 'I-NP': 3, 'B-VP': 4, 'I-VP': 5, 'B-SBAR': 6, 'O': 7, 'B-ADJP': 8}\n",
      "Training feature data is .....\n",
      "((3, 7), {1184, 1186, 1188, 1190, 1192, 1194, 1196, 1178, 1180, 1182})\n",
      "((-1, 7), {1185, 1187, 1189, 1191, 1193, 1195, 1197, 1179, 1181, 1183})\n",
      "((3, 2), {971, 556})\n",
      "((-1, 2), {972, 557})\n",
      "((3, 6), {458})\n",
      "((-1, 6), {459})\n",
      "((2, 1), {741})\n",
      "((-1, 1), {742})\n",
      "((3, 4), {1622})\n",
      "((-1, 4), {1623})\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features are\", F.num_features)\n",
    "print(\"length of feature dic is\", len(F.feature_dic))\n",
    "print(\"Labels are :\", F.label_dic)\n",
    "print(\"Training feature data is .....\")\n",
    "#Training feature data is [paragraph][sentence][word] dic of [prev y, y] or current[-1,y] with a index of where it is in features\n",
    "for l in F.training_feature_data[0][:][:]:\n",
    "    print(l)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now create feature data\n",
    "\n",
    "def get_feature_data(self, X, t, features):\n",
    "    \"\"\"\n",
    "    INPUT - \n",
    "            feature_dic[f][(prev_y, y)]     Now filled in from previous loop\n",
    "    OUTPUT -\n",
    "            feature_list_dic[(prev_y, y)] = feature_id\n",
    "\n",
    "    \"\"\"\n",
    "    feature_list_dic = dict()\n",
    "    \n",
    "    for f in features:\n",
    "        # feature_dic[f][(prev_y, y)]\n",
    "\n",
    "        for (prev_y, y), feature_id in self.feature_dic[f].items():  # get label and feature id\n",
    "            labels = (prev_y, y)\n",
    "            if labels in feature_list_dic.keys():\n",
    "                feature_list_dic[labels].add(feature_id)        \n",
    "            else:\n",
    "                feature_list_dic[labels] = {feature_id}\n",
    "                           \n",
    "    l = [ (labels, feature_ids) for labels, feature_ids in feature_list_dic.items() ]\n",
    "    return l\n",
    "        \n",
    "    def _get_training_feature_data(self):\n",
    "        return [ [ self.get_feature_list(X, t) for t in range(len(X))  ] for X, _ in self.d]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def get_feature_list(self, X, t):\n",
    "    #                 feature_dic[f][(prev_y, y)]\n",
    "    feature_list_dic = dict()\n",
    "    for feature_string in self.feature_func(X, t):\n",
    "        for (prev_y, y), feature_id in self.feature_dic[feature_string].items():\n",
    "            if (prev_y, y) in feature_list_dic.keys():\n",
    "                feature_list_dic[(prev_y, y)].add(feature_id)\n",
    "            else:\n",
    "                feature_list_dic[(prev_y, y)] = {feature_id}\n",
    "\n",
    "    return [ ((prev_y, y), feature_ids) for (prev_y, y), feature_ids in feature_list_dic.items() ]\n",
    "\n",
    "\n",
    "    \n",
    "    training_feature_data = self._get_training_feature_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model with the feature data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "466px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "2087px",
    "right": "20px",
    "top": "143px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
